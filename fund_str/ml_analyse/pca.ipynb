{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2cbba4-6487-407a-b36b-c3604789033c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Тестируем модель Principal Components Analysis с разными связками:\n",
    "+ собираем таблицу\n",
    "+ подготавливаем таблицу\n",
    "+ обрабатываем по разному через PCA\n",
    "+ пропускаем через Gaussian NB\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb07fae3-ccf7-47ce-b508-e2901573386f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# external api\n",
    "import fundamentalanalysis as fa\n",
    "import yfinance as yf\n",
    "\n",
    "# data analytic \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# additional liberies\n",
    "import datetime\n",
    "import statistics as st\n",
    "import itertools\n",
    "\n",
    "# ML strategies\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# ML analyse\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# vizualization\n",
    "import pylab as plb\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cba9819-57ad-4070-a2ad-9a8450433c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "903e3d2c-af47-4c40-be9f-950264bcf6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# api_key = '00ef9804fcde0edd93b1b4821ee2f06a'  #job.chap@icloud.com\n",
    "# api_key = 'c81352430e2fe3c941faf0814227562b'  #jobs.chaps@gmail.com\n",
    "api_key = 'a765d11740cccfb61177da0ad8699d1e'  #job.chap@gmail.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b7060d6-c9fc-4f2e-883d-a773d5669560",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Тикеры '''\n",
    "tick = 'F'  # поменял название переменно ticker на tick, для настройки по одной акции\n",
    "# tickers_list = ['F', 'AAPL' ,'ADBE', 'COP', 'AMAT', 'MFGP', 'FISV', 'ASAN', 'ALIT', 'DAVA', 'NCR', 'SMTC', 'EXLS', 'JKHY', 'ORCL', 'APPS', 'U', 'FICO', 'WEX', 'TXN', 'GDDY', 'CRSR', 'MANH', 'LITE', 'MANH', 'TENB', 'ACLS', 'LPL']\n",
    "                # 'GWRE', 'PAYC', 'NCNO', 'APH', 'AVT', 'COUP']\n",
    "tickers_list = ['AAPL', 'SYNA', 'PLUS', 'BSY', 'PYPL', 'ADSK', 'AZPN', 'SPSC', 'FORM', 'DOCU', 'VPG', 'CRWD', 'WDC', 'MVIS','ADBE', 'VSAT', 'GDRX', 'DNB', 'PLTR', 'FIVN', 'NTCT', 'FROG']\n",
    "                \n",
    "''' для фильтрации'''\n",
    "# filt_start_date = '2000'\n",
    "# filt_finish_date = '2022'\n",
    "\n",
    "\n",
    "''' время '''\n",
    "stime = '2000-01-01'\n",
    "ftime = '2023-02-01'\n",
    "period = '1mo'  # '1d' '1wk'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8ab537-0b34-4ae7-a06e-0c87fcd9b765",
   "metadata": {},
   "source": [
    "Класс Fund ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f94a1835-968b-41c0-9340-4f81584beda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fund_ticker:\n",
    "    def __init__(self, tick, stime, ftime, api_key_fund):\n",
    "        self.tick = tick\n",
    "        self.stime = stime\n",
    "        self.ftime = ftime\n",
    "        self.api_key_fund = api_key_fund\n",
    "        \n",
    "        \n",
    "    def _change_index_plus_one(self, df):\n",
    "        \"\"\" добавлят цифру к году в фундаментальные api, чтобы видень данные как начало года, а не как факт \n",
    "        \"\"\"\n",
    "        \n",
    "        df_index = df.index.to_list()\n",
    "        \n",
    "        for i in range(len(df_index)):\n",
    "            df_index[i] = str(int(df_index[i])+1)\n",
    "            \n",
    "        df['Date_index'] = df_index\n",
    "        \n",
    "        df = df.set_index('Date_index')\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    def get_key_metr(self):\n",
    "        \"\"\" получаем df с key_metrics\n",
    "        \"\"\"\n",
    "        \n",
    "        df_key_metrics = fa.key_metrics(self.tick, self.api_key_fund, period='annual')\n",
    "        df_key_metrics = self._change_index_plus_one(df_key_metrics.T)\n",
    "        \n",
    "        return df_key_metrics\n",
    "    \n",
    "    def get_income_statement(self):\n",
    "        \"\"\" получаем df с income_statement\n",
    "        \"\"\"   \n",
    "        \n",
    "        income_statement = fa.income_statement(self.tick, self.api_key_fund, period='annual')\n",
    "        income_statement = self._change_index_plus_one(income_statement.T)\n",
    "        \n",
    "        return income_statement\n",
    "        \n",
    "    \n",
    "    def get_balance_sheet_statement(self):\n",
    "        \"\"\" получаем df с balance_sheet_statement\n",
    "        \"\"\"  \n",
    "        \n",
    "        balance_sheet_statement = fa.balance_sheet_statement(self.tick, self.api_key_fund, period='annual')\n",
    "        balance_sheet_statement = self._change_index_plus_one(balance_sheet_statement.T)\n",
    "        \n",
    "        return balance_sheet_statement\n",
    "\n",
    "    def get_cash_flow_statement(self):   \n",
    "        \"\"\" получаем df с cash_flow_statement\n",
    "        \"\"\"    \n",
    "        \n",
    "        cash_flow_statement = fa.cash_flow_statement(self.tick, self.api_key_fund, period='annual')\n",
    "        cash_flow_statement = self._change_index_plus_one(cash_flow_statement.T)\n",
    "        \n",
    "        return cash_flow_statement\n",
    "\n",
    "    def get_financial_ratios(self):    \n",
    "        \"\"\" получаем df с financial_ratios\n",
    "        \"\"\"\n",
    "        \n",
    "        financial_ratios = fa.financial_ratios(self.tick, self.api_key_fund, period='annual')\n",
    "        financial_ratios = self._change_index_plus_one(financial_ratios.T)\n",
    "        \n",
    "        return financial_ratios\n",
    "\n",
    "    def get_financial_statement_growth(self):\n",
    "        \"\"\" получаем df с financial_statement_growth\n",
    "        \"\"\" \n",
    "        \n",
    "        financial_statement_growth = fa.financial_statement_growth(self.tick, self.api_key_fund, period='annual')\n",
    "        financial_statement_growth = self._change_index_plus_one(financial_statement_growth.T)\n",
    "        \n",
    "        return financial_statement_growth\n",
    "    \n",
    "    \n",
    "    def all_metrics(self):\n",
    "        \"\"\" df со всеми колонками = конкатенация колонок со всех полученных таблиц со значениями\n",
    "        \"\"\"\n",
    "        \n",
    "        df_km = self.get_key_metr()\n",
    "        df_is = self.get_income_statement()\n",
    "        df_bss = self.get_balance_sheet_statement()\n",
    "        df_cfs = self.get_cash_flow_statement()\n",
    "        df_fr = self.get_financial_ratios()\n",
    "        df_fsg = self.get_financial_statement_growth()\n",
    "        \n",
    "        df_all_fa_columns = pd.concat([df_km,\n",
    "                                       df_is,\n",
    "                                       df_bss,\n",
    "                                       df_cfs,\n",
    "                                       df_fr,\n",
    "                                       df_fsg\n",
    "                                       ], axis=1)\n",
    "        \n",
    "        \"\"\" убраем дубликаты колонок \"\"\"\n",
    "        df_all_fa_columns = df_all_fa_columns.loc[:,~pd.concat([df_km,\n",
    "                                                                df_is,\n",
    "                                                                df_bss,\n",
    "                                                                df_cfs,\n",
    "                                                                df_fr,\n",
    "                                                                df_fsg\n",
    "                                                                ], axis=1).columns.duplicated()]\n",
    "        \n",
    "        \n",
    "        \"\"\" удаляются не используемые колонки \"\"\"\n",
    "        df_all_fa_columns = df_all_fa_columns.drop(['period', 'reportedCurrency', 'cik', 'fillingDate', 'calendarYear', 'link', 'finalLink'], axis=1)        \n",
    "        \n",
    "        return df_all_fa_columns\n",
    "    \n",
    "    def all_metrics_period(self):\n",
    "        \"\"\" df со всеми колонками отфильтрованная в нужный период\n",
    "        \"\"\"\n",
    "        \n",
    "        df = self.all_metrics()\n",
    "        \n",
    "        # берем из дат 4е символа\n",
    "        start = self.stime[:4]\n",
    "        finish = self.ftime[:4]\n",
    "        \n",
    "        df_filt = df.loc[finish:start].copy(deep=True)\n",
    "        \n",
    "        return df_filt  \n",
    "        \n",
    "    def get_yahoo_prices(self, ticker):\n",
    "        ''' получаем цены из yahoo_finance и меняем методом индекс\n",
    "        '''\n",
    "        ticker = yf.Ticker(ticker)\n",
    "\n",
    "        df = ticker.history(start=self.stime, end=self.ftime, interval='1mo')\n",
    "        x = pd.DataFrame(df)\n",
    "        x.rename(columns={\"Close\": self.tick}, inplace=True)\n",
    "        z = x.drop(columns=[\"Open\", \"High\", \"Low\", \"Volume\", \"Dividends\", \"Stock Splits\"])\n",
    "        \n",
    "        return z\n",
    "    \n",
    "    def _change_index_yahoo(self, df):\n",
    "        ''' сокращаем индекс из dataframe yahoo\n",
    "        '''\n",
    "        \n",
    "\n",
    "        df_index = df.index.to_list()\n",
    "        for i in range(len(df_index)):\n",
    "            t = df_index[i].date()\n",
    "            df_index[i] = t.strftime('%Y-%m-%d')\n",
    "        df['Date_index'] = df_index\n",
    "        df = df.set_index('Date_index')\n",
    "        return df  \n",
    "    \n",
    "    def _get_years_prices(self, df, list_years):\n",
    "        ''' из датафрейма цен получает цены на начало года\n",
    "        '''\n",
    "        \n",
    "        # df = all_metrics_period()\n",
    "        # index_year = df.index.to_list()\n",
    "        \n",
    "        year_prices = []\n",
    "        for i in range(len(list_years)):\n",
    "            x = int(list_years[i])\n",
    "            x = str(x)\n",
    "            r = df.loc[f'{x}-01-01']\n",
    "            r = float(r)\n",
    "            year_prices.append(r)\n",
    "\n",
    "        return year_prices\n",
    "    \n",
    "    \n",
    "    def df_with_prices(self):\n",
    "        \n",
    "        df = self.all_metrics_period()\n",
    "        \n",
    "        df_ticker = self._change_index_yahoo(self.get_yahoo_prices(self.tick))  # ценs нужной акции + измененный индекс\n",
    "        df_snp = self._change_index_yahoo(self.get_yahoo_prices('^GSPC'))  # цены SNP + измененный индекс       \n",
    "        \n",
    "        index_years = df.index.to_list()\n",
    "        \n",
    "        df_ticker_years = self._get_years_prices(df_ticker, index_years)\n",
    "        df_snp_years = self._get_years_prices(df_snp, index_years)\n",
    "        \n",
    "        \n",
    "        df['ticker'] = self.tick\n",
    "        df['stock_price'] = df_ticker_years\n",
    "        df['SNP_price'] = df_snp_years\n",
    "        \n",
    "        return df\n",
    "        \n",
    "        \n",
    "    def _change_percent_all_columns(self):\n",
    "        ''' получаем относительные значения, с исключениями:\n",
    "        а) если не получается обработать вообще - пропускает\n",
    "        б) если уходит ниже нуля или выше, то назначает значение 'Minus' или 'Plus'\n",
    "        '''\n",
    "        df = self.df_with_prices()\n",
    "        x = df.columns.to_list()\n",
    "        \n",
    "        for i in range(len(x)):\n",
    "            v = df[x[i]].to_list()\n",
    "            l = []\n",
    "            for y in range(len(v)):\n",
    "                try:\n",
    "                    if y != len(v):\n",
    "                        if v[y] < 0 and v[y+1] > 0:\n",
    "                            l.append('Minus')\n",
    "                        elif v[y] > 0 and v[y+1] < 0:\n",
    "                            l.append('Plus')\n",
    "                        else:\n",
    "                            vv = (v[y] / (v[y+1] / 100)) - 100\n",
    "                            l.append(vv)  \n",
    "                    else:\n",
    "                        vv = 0\n",
    "                        l.append(vv)\n",
    "                except:\n",
    "                    l.append(0)\n",
    "\n",
    "            df_copy = df.copy() \n",
    "            df_copy[f'change % {x[i]}'] = l\n",
    "            df = pd.concat([df, df_copy[f'change % {x[i]}']], axis=1)\n",
    "            \n",
    "        df = df.drop(['change % acceptedDate','change % ticker'], axis=1)\n",
    "        \n",
    "        \"\"\" удаляем последнюю строку, где значения равны 0\"\"\"\n",
    "        df = df.drop(df.index[-1])\n",
    "            \n",
    "        return df\n",
    "        \n",
    "    \n",
    "    def df_add_two_next_percent_years(self):\n",
    "        ''' добавлет два следующих года для акции и для рынка\n",
    "        + если нет, то добавляет None\n",
    "        '''\n",
    "        \n",
    "        df = self._change_percent_all_columns()\n",
    "        \n",
    "        # первый год акция\n",
    "        stock_prices = df['change % stock_price'].to_list()\n",
    "        stock_prices_first = ['None'] + stock_prices\n",
    "        stock_prices_first.pop()\n",
    "\n",
    "        # второй год акция\n",
    "        stock_prices_second = ['None'] + stock_prices_first\n",
    "        stock_prices_second.pop()\n",
    "\n",
    "        # первый год рынок\n",
    "        snp_prices = df['change % stock_price'].to_list()\n",
    "        snp_prices_first = ['None'] + snp_prices\n",
    "        snp_prices_first.pop()\n",
    "\n",
    "        # второй год рынок\n",
    "        snp_prices_second = ['None'] + snp_prices_first\n",
    "        snp_prices_second.pop()\n",
    "\n",
    "        df_copy = df.copy()\n",
    "        df_copy['stock_plus_1year'] = stock_prices_first\n",
    "        df_copy['stock_plus_2year'] = stock_prices_second\n",
    "        df_copy['snp_plus_1year'] = snp_prices_first\n",
    "        df_copy['snp_plus_2year'] = snp_prices_second\n",
    "\n",
    "        return df_copy    \n",
    "\n",
    "    \n",
    "    def df_all_with_category(self):\n",
    "        ''' добавляем категоричные значение\n",
    "        ''' \n",
    "        \n",
    "        df = self.df_add_two_next_percent_years()\n",
    "        \n",
    "        t = []\n",
    "        for i in range(len(df['stock_plus_1year'])):\n",
    "            try:\n",
    "                if df['stock_plus_1year'][i] > 0:\n",
    "                    t.append(1)\n",
    "                else:\n",
    "                    t.append(0)\n",
    "            except:\n",
    "                t.append('None')\n",
    "\n",
    "        df['categor_1year'] = t        \n",
    "\n",
    "        t = []\n",
    "        for i in range(len(df['stock_plus_2year'])):\n",
    "            try:\n",
    "                if df['stock_plus_2year'][i] > 0:\n",
    "                    t.append(1)\n",
    "                else:\n",
    "                    t.append(0)\n",
    "            except:\n",
    "                t.append('None')\n",
    "\n",
    "        df['categor_2year'] = t    \n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a083547-ffad-4472-affb-de955b30f60f",
   "metadata": {},
   "source": [
    "Класс Prepare_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cce98b40-11ac-4acb-b4f7-8974626dc959",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prepare_data:\n",
    "    def __init__(self, tickers_list, stime, ftime, api_key):\n",
    "        self.ticker_list = tickers_list\n",
    "        self.stime = stime\n",
    "        self.ftime = ftime\n",
    "        self.api_key = api_key\n",
    "        self.df = Fund_ticker(tickers_list[0], stime, ftime, api_key).df_all_with_category() # сразу получаем \n",
    "        \n",
    "        \n",
    "    def change_names_for_combimation(self, df):  # в процессе \n",
    "        \"\"\" получаем колонки которыем мы будем использовать для создания комбинаций для ml\n",
    "        Требования: \n",
    "        - содержат 'change %' - для анализа по отновсительным значениям\n",
    "        - только данные формата int и float (исключаем Nan, Minus, Plus и прочее) - чтобы использовать больше моделей ML и более точно\n",
    "        \"\"\"\n",
    "        \n",
    "        df_new = df\n",
    "        \n",
    "        list_df_columns = df_new.columns.to_list()\n",
    "        \n",
    "\n",
    "        t = []\n",
    "        for i in range(len(list_df_columns)):\n",
    "            if 'change %' in list_df_columns[i]  and df[f'{list_df_columns[i]}'].dtype == float: \n",
    "                t.append(list_df_columns[i])\n",
    "            else:\n",
    "                pass\n",
    "     \n",
    "        return t\n",
    "    \n",
    "    def compination_change_names(self, df):\n",
    "        \"\"\" получаем комбинации возможных значений\n",
    "        \"\"\"\n",
    "        \n",
    "        names_list = self.change_names_for_combimation(df)\n",
    "        combinations = list(itertools.combinations(names_list , 2))\n",
    "        \n",
    "        return combinations\n",
    "    \n",
    "    def split_combinations(self, df):\n",
    "        \"\"\" разбиваем комбинации на более короткие (по 100 штук)\n",
    "        \"\"\"\n",
    "                \n",
    "        values_combo = self.compination_change_names(df)\n",
    "        split_lists = [values_combo[i:i+100] for i in range(0, len(values_combo), 100)]\n",
    "             \n",
    "        return split_lists\n",
    "    \n",
    "    \n",
    "    def concat_tickers_tables(self):\n",
    "        \"\"\" загружаем список тикеров, получаем обработанную таблицу с объединенными тикерами\n",
    "        \"\"\"\n",
    "    \n",
    "        tick_list = self.ticker_list\n",
    "    \n",
    "        \n",
    "        try:\n",
    "            for i in range(len(tick_list)):\n",
    "                if i == 0:\n",
    "                    df = Fund_ticker(tick_list[i], self.stime, self.ftime, self.api_key).df_all_with_category()\n",
    "                    print(tick_list[i])\n",
    "                else:\n",
    "                    try:\n",
    "                        df = pd.concat([df, Fund_ticker(tick_list[i], self.stime, self.ftime, self.api_key).df_all_with_category()], ignore_index=True)\n",
    "                        print(tick_list[i])\n",
    "                    except:\n",
    "                        print(f'{tick_list[i]} = не прошел')\n",
    "        except:\n",
    "            df = 0\n",
    "\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def df_clean_changes(self):\n",
    "    \n",
    "        \"\"\" очищаем строки с None df по колонке \"categor_1year\" если целевые величины будут браться по ней\n",
    "        \"\"\"\n",
    "        \n",
    "        df = self.concat_tickers_tables()\n",
    "        \n",
    "        \n",
    "        # выбираем колонки, содержащие слово \"нет\" в значениях\n",
    "        cols_with_word = df.applymap(lambda x: 'Plus' in str(x)).any()\n",
    "\n",
    "        # удаляем выбранные колонки\n",
    "        df.drop(cols_with_word[cols_with_word == True].index, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "        cols_with_word = df.applymap(lambda x: 'Minus' in str(x)).any()\n",
    "\n",
    "\n",
    "        # удаляем выбранные колонки\n",
    "        df.drop(cols_with_word[cols_with_word == True].index, axis=1, inplace=True)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def df_clean_first_year_ct(self):\n",
    "        \"\"\" очищаем строки с None df по колонке \"categor_1year\" если целевые величины будут браться по ней\n",
    "        \"\"\"\n",
    "        \n",
    "        df = self.df_clean_changes()\n",
    "        \n",
    "        df = df.drop(df[df['categor_1year'] == 'None'].index)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def df_clean_second_year_ct(self):\n",
    "        \"\"\" очищаем строки с None df по колонке \"categor_1year\" если целевые величины будут браться по ней\n",
    "        \"\"\"\n",
    "        \n",
    "        df = self.df_clean_changes()\n",
    "        \n",
    "        df = df.drop(df[df['categor_2year'] == 'None'].index)\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58218fcd-7b6f-4244-b88c-073faa6088ec",
   "metadata": {},
   "source": [
    "ML_analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f999968-2331-444f-99f8-098420d3605a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCA_analyse:\n",
    "    \"\"\" модели для анализа таблицы\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, tickers_list, stime, ftime, api_key):\n",
    "        self.tickers_list = tickers_list\n",
    "        self.stime = stime\n",
    "        self.ftime = ftime\n",
    "        self.api_key = api_key\n",
    "        \n",
    "    def pca_general_comp(self):\n",
    "        \"\"\" анализ главных компонентов Principal Components Analysis\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        df = Prepare_data(self.tickers_list, self.stime, self.ftime, self.api_key).df_clean_second_year_ct()\n",
    "        change_names = Prepare_data(self.tickers_list, self.stime, self.ftime, self.api_key).change_names_for_combimation(df)\n",
    "        \n",
    "        X = df[change_names+[\"stock_plus_1year\", \"stock_plus_2year\", \"snp_plus_1year\", \"snp_plus_2year\"]]\n",
    "        y = df[\"categor_2year\"]\n",
    "        \n",
    "        X = preprocessing.SplineTransformer().fit(X).transform(X)\n",
    "        \n",
    "        model = PCA()\n",
    "        results = model.fit(X)\n",
    "        Z = results.transform(X)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def vizualization_general_comp_pca(self):\n",
    "        \"\"\" визуализируем итог главных компонентов PCA\n",
    "        \"\"\"\n",
    "        \n",
    "        results = self.pca_general_comp()\n",
    "        plb.plot(results.explained_variance_)\n",
    "        plb.show()\n",
    "        \n",
    "\n",
    "    def table_general_comp_pca(self):\n",
    "        \"\"\" получаем таблицу итога главных компонентов PCA\n",
    "        \"\"\"\n",
    "        \n",
    "        results = self.pca_general_comp()\n",
    "        \n",
    "        y = results.explained_variance_\n",
    "\n",
    "        df = pd.DataFrame(np.round(y, decimals=4), columns=['Influence of components'])\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def nbg_without_pca(self):\n",
    "        \n",
    "        df = Prepare_data(self.tickers_list, self.stime, self.ftime, self.api_key).df_clean_second_year_ct()\n",
    "        change_names = Prepare_data(self.tickers_list, self.stime, self.ftime, self.api_key).change_names_for_combimation(df)\n",
    "        \n",
    "        X = df[change_names+[\"stock_plus_1year\", \"stock_plus_2year\", \"snp_plus_1year\", \"snp_plus_2year\"]]\n",
    "        y = df[\"categor_2year\"]\n",
    "        \n",
    "        X = preprocessing.SplineTransformer().fit(X).transform(X)\n",
    "        y = preprocessing.LabelEncoder().fit_transform(y)\n",
    "        \n",
    "        \n",
    "        gnb = GaussianNB()\n",
    "        fit = gnb.fit(X,y)\n",
    "        pred = fit.predict(X)\n",
    "        \n",
    "        return confusion_matrix(pred, y)\n",
    "    \n",
    "    \n",
    "#     def pca_component(self):   # не смог получить корректное, так как pca возращает 700 столбцов (как идея создать range для всех них)\n",
    "#         \"\"\" выводим компонент pca\n",
    "#         \"\"\"\n",
    "    \n",
    "        \n",
    "#         df = Prepare_data(self.tickers_list, self.stime, self.ftime, self.api_key).df_clean_second_year_ct()\n",
    "#         change_names = Prepare_data(self.tickers_list, self.stime, self.ftime, self.api_key).change_names_for_combimation(df)\n",
    "        \n",
    "#         X = df[change_names+[\"stock_plus_1year\", \"stock_plus_2year\", \"snp_plus_1year\", \"snp_plus_2year\"]]\n",
    "#         y = df[\"categor_2year\"]\n",
    "        \n",
    "#         X = preprocessing.SplineTransformer().fit(X).transform(X)\n",
    "        \n",
    "#         model = PCA()\n",
    "#         results = model.fit(X)\n",
    "#         Z = results.transform(X)\n",
    "        \n",
    "        \n",
    "#         columnds_for_df = change_names+[\"stock_plus_1year\", \"stock_plus_2year\", \"snp_plus_1year\", \"snp_plus_2year\"]\n",
    "#         df1 = pd.DataFrame(results.components_, columns=columnds_for_df)\n",
    "        \n",
    "#         return df1\n",
    "\n",
    "    def nbg_pca(self):\n",
    "        \"\"\" формируем пять principal components и моделируем Gaussian Naive Bayes\n",
    "        \"\"\"\n",
    "        \n",
    "        # 1. Загрузите данные в Pandas DataFrame\n",
    "        df = Prepare_data(tickers_list, stime, ftime, api_key).df_clean_second_year_ct()\n",
    "\n",
    "\n",
    "        # 2. Выделите признаки, которые вы хотите использовать для PCA\n",
    "        change_names = Prepare_data(tickers_list, stime, ftime, api_key).change_names_for_combimation(df)\n",
    "        change_names = change_names +[\"stock_plus_1year\", \"stock_plus_2year\", \"snp_plus_1year\", \"snp_plus_2year\"]\n",
    "\n",
    "     \n",
    "        # 3. Нормализуйте признаки, если это необходимо\n",
    "        X = (df[change_names] - df[change_names].mean()) / df[change_names].std()\n",
    "\n",
    "        # 4. Создайте объект PCA\n",
    "        pca = PCA(n_components=5)\n",
    "        \n",
    "        # 5. Обучите модель PCA на данных\n",
    "        pca.fit(X)\n",
    "        \n",
    "        # 6. Преобразуйте данные\n",
    "        transformed_data = pca.transform(X)\n",
    "        \n",
    "        # 7. Создайте новый DataFrame с преобразованными данными\n",
    "        pca_data = pd.DataFrame(data=transformed_data, columns=['PC1', 'PC2', 'PC3', 'PC4', 'PC5'])        \n",
    "        \n",
    "        # 8. Добавьте метки классов, если они есть\n",
    "        if 'class' in df.columns:\n",
    "            pca_data['class'] = data['class']\n",
    "            \n",
    "        # 9.добавляем целевые величины\n",
    "        y = df[\"categor_2year\"].values\n",
    "\n",
    "        y = y.astype(float)\n",
    "\n",
    "        # обучение классификатора Gaussian Naive Bayes\n",
    "        classifier = GaussianNB()\n",
    "        fit = classifier.fit(X, y)\n",
    "\n",
    "        pred = fit.predict(X)\n",
    "\n",
    "        return confusion_matrix(pred, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75e0c326-f852-4a47-a5bc-54db14d5ac76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL\n",
      "SYNA = не прошел\n",
      "PLUS\n",
      "BSY = не прошел\n",
      "PYPL = не прошел\n",
      "ADSK\n",
      "AZPN\n",
      "SPSC = не прошел\n",
      "FORM = не прошел\n",
      "DOCU = не прошел\n",
      "VPG = не прошел\n",
      "CRWD = не прошел\n",
      "WDC\n",
      "MVIS\n",
      "ADBE\n",
      "VSAT\n",
      "GDRX = не прошел\n",
      "DNB = не прошел\n",
      "PLTR = не прошел\n",
      "FIVN = не прошел\n",
      "NTCT\n",
      "FROG = не прошел\n"
     ]
    }
   ],
   "source": [
    "result = PCA_analyse(tickers_list, stime, ftime, api_key).nbg_pca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4f34d1d-7385-4f3a-a2be-917aee52951d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 32,   7],\n",
       "       [ 33, 117]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d41935-d5bf-44f6-bd88-89649d4ec2a3",
   "metadata": {},
   "source": [
    "finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5aa872e7-9485-42c8-8c8e-f7d71e37a99d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "150/180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2365031-66a4-41e3-b80d-8e5bb1dcefb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
